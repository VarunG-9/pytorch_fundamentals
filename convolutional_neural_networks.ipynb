{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNLpDMrwAAZiAEuWsI1u+D3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"551b6ac2286346fca4a2b8af893d2a49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_022e51fc62a94dfcba3ee410a30d0655","IPY_MODEL_d22617b05c474c39811aa1df5c04a28f","IPY_MODEL_ac2805c0f6c9426e8d629aedb73e3156"],"layout":"IPY_MODEL_f2f0ce7adccb43f1adfdcf3c986ad87a"}},"022e51fc62a94dfcba3ee410a30d0655":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e6d0dede2364d99ad66914a8849c08d","placeholder":"​","style":"IPY_MODEL_e86ffc7e6c274988b8b25dcf91c1f44c","value":"  0%"}},"d22617b05c474c39811aa1df5c04a28f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bbde04f663245a4b07a1887ee7dd7eb","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af61d0bc1a3e42f98c048fa60eb9f112","value":0}},"ac2805c0f6c9426e8d629aedb73e3156":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_578efbc2c0604d0f94596b03bf164ee8","placeholder":"​","style":"IPY_MODEL_71dd346a1e7945d6b4aa383dae791c32","value":" 0/3 [00:00&lt;?, ?it/s]"}},"f2f0ce7adccb43f1adfdcf3c986ad87a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e6d0dede2364d99ad66914a8849c08d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e86ffc7e6c274988b8b25dcf91c1f44c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bbde04f663245a4b07a1887ee7dd7eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af61d0bc1a3e42f98c048fa60eb9f112":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"578efbc2c0604d0f94596b03bf164ee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71dd346a1e7945d6b4aa383dae791c32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"id":"Aio1tFjiON7v","executionInfo":{"status":"ok","timestamp":1717127945620,"user_tz":-330,"elapsed":611,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"outputs":[],"source":["# Import PyTorch\n","\n","import torch\n","from torch import nn\n","import torchvision\n","from torchvision import datasets\n","from torchvision import transforms\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader\n","\n","# Import matplotlib\n","\n","import matplotlib.pyplot as plt\n","device = 'cuda' if torch.cuda.is_available else 'cpu'"]},{"cell_type":"code","source":["def accuracy_fn(y_true, y_pred):\n","    \"\"\"Calculates accuracy between truth labels and predictions.\n","\n","    Args:\n","        y_true (torch.Tensor): Truth labels for predictions.\n","        y_pred (torch.Tensor): Predictions to be compared to predictions.\n","\n","    Returns:\n","        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n","    \"\"\"\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","    return acc"],"metadata":{"id":"mTUO7pqM1o1S","executionInfo":{"status":"ok","timestamp":1717127946219,"user_tz":-330,"elapsed":14,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Getting a dataset\n","train_data = datasets.FashionMNIST(\n","    root=\"data\", # where to download data\n","    train=True,\n","    download=True, # download yes/no?\n","    transform=torchvision.transforms.ToTensor(), # transform on the data\n","    target_transform=None # how we want to transform the label\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\", # where to download data\n","    train=False,\n","    download=True, # download yes/no?\n","    transform=torchvision.transforms.ToTensor(), # transform on the data\n","    target_transform=None # how we want to transform the label\n",")"],"metadata":{"id":"uyLQmIig1q69","executionInfo":{"status":"ok","timestamp":1717127946219,"user_tz":-330,"elapsed":14,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)"],"metadata":{"id":"LW8QC6x41r-Q","executionInfo":{"status":"ok","timestamp":1717127946219,"user_tz":-330,"elapsed":13,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["class_names = train_data.classes"],"metadata":{"id":"x9ob94s25bup","executionInfo":{"status":"ok","timestamp":1717127946219,"user_tz":-330,"elapsed":13,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","\n","\n","def train_step(model: torch.nn.Module,\n","               data_loader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               accuracy_fn,\n","               device: torch.device=device):\n","  \"\"\" Performs a training with model trying to learn on the dataloader\"\"\"\n","  train_loss, train_acc = 0, 0\n","\n","# Set the seed and start the timer\n","  model.train()\n","\n","  # Add a loop to iterate through the dataloader\n","  for batch, (X, y) in enumerate(train_dataloader):\n","    # Put data on target device\n","    X, y = X.to(device), y.to(device)\n","\n","    # 1. Forward Pass\n","    y_pred = model(X)\n","\n","    # 2. Calculate loss\n","    loss = loss_fn(y_pred, y)\n","    train_loss += loss\n","    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n","    # 3. Optimizer zero grad\n","    optimizer.zero_grad()\n","\n","    # 4. Loss backward\n","    loss.backward()\n","\n","    # 5. Optimizer step\n","    optimizer.step()\n","\n","    if batch % 400 == 0:\n","      print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)}\")\n","\n","  train_loss /= len(data_loader)\n","  train_acc /= len(data_loader)\n","  print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"],"metadata":{"id":"40nXQ2TZ12nT","executionInfo":{"status":"ok","timestamp":1717127946219,"user_tz":-330,"elapsed":13,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def test_step(model: torch.nn.Module,\n","              data_loader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              accuracy_fn,\n","              device: torch.device=device):\n","  \"\"\"\n","  Performs a test step with the model given.\n","  \"\"\"\n","  # Testing\n","  test_loss, test_acc = 0, 0\n","  model.eval()\n","  with torch.inference_mode():\n","    for X_test, y_test in data_loader:\n","      X_test, y_test = X_test.to(device), y_test.to(device)\n","      # 1. Forward Pass\n","      test_pred = model(X_test)\n","      # 2. Calculate Loss\n","      test_loss += loss_fn(test_pred, y_test)\n","      # 3. Calculate Accuracy\n","      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n","\n","    test_loss /= len(data_loader)\n","    test_acc /= len(data_loader)\n","\n","  print(f\"\\nTest Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"],"metadata":{"id":"RsNRmWmO14Mw","executionInfo":{"status":"ok","timestamp":1717127946220,"user_tz":-330,"elapsed":13,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class FashionMNISTModelV2(nn.Module):\n","  \"\"\"\n","  Model architecture that replicates the TinyVGG model from the CNN Explainer website\n","  \"\"\"\n","  def __init__(self, input_shape: int, output_shape: int, hidden_units: int):\n","    super().__init__()\n","    self.conv_block_1 = nn.Sequential(\n","        nn.Conv2d(in_channels=input_shape,\n","                  out_channels=hidden_units,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1), # values we can set ourself in our neural networks that hold hyperparameters\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_units,\n","                  out_channels=hidden_units,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2)\n","    )\n","\n","    self.conv_block_2 = nn.Sequential(\n","        nn.Conv2d(in_channels=hidden_units,\n","                  out_channels=hidden_units,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_units,\n","                  out_channels=hidden_units,\n","                  kernel_size=3,\n","                  stride=1,\n","                  padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2)\n","    )\n","\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(in_features=hidden_units*7*7, # Trick to calculate this.\n","                  out_features=output_shape\n","                  )\n","    )\n","\n","  def forward(self, x):\n","    x = self.conv_block_1(x)\n","    print(x.shape)\n","    x = self.conv_block_2(x)\n","    print(x.shape)\n","    x = self.classifier(x)\n","    return x\n"],"metadata":{"id":"i6PiTetu15G0","executionInfo":{"status":"ok","timestamp":1717127946220,"user_tz":-330,"elapsed":13,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","model_2 = FashionMNISTModelV2(input_shape=1, hidden_units=10, output_shape=len(class_names)).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQuB7n-B5DEB","executionInfo":{"status":"ok","timestamp":1717127946220,"user_tz":-330,"elapsed":13,"user":{"displayName":"Varun G","userId":"00704873837361776795"}},"outputId":"852bc832-63ba-40c3-8ee8-1bc5159e4cd0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n","  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"]}]},{"cell_type":"code","source":["# Stepping through nn.Conv2d\n","torch.manual_seed(42)\n","\n","# Create a batch of images\n","images = torch.randn(size=(32,3,64,64))\n","test_image = images[0]\n","\n","print(f\"Image batch shape: {images.shape}\")\n","print(f\"Single image shape: {test_image.shape}\")\n","print(f\"Test image:\\n {test_image}\")"],"metadata":{"id":"63vn4wB95tyg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717127946220,"user_tz":-330,"elapsed":11,"user":{"displayName":"Varun G","userId":"00704873837361776795"}},"outputId":"e9148fd3-6b52-4867-c5c0-ca9457a11fcf"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Image batch shape: torch.Size([32, 3, 64, 64])\n","Single image shape: torch.Size([3, 64, 64])\n","Test image:\n"," tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n","         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n","         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n","         ...,\n","         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n","         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n","         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n","\n","        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n","         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n","         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n","         ...,\n","         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n","         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n","         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n","\n","        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n","         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n","         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n","         ...,\n","         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n","         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n","         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"]}]},{"cell_type":"code","source":["# Create a single Conv2d Layer\n","conv_layer = nn.Conv2d(in_channels=3,\n","                       out_channels=10,\n","                       kernel_size=3,\n","                       stride=1,\n","                       padding=0)\n","\n","conv_output = conv_layer(test_image.unsqueeze(0))\n","conv_output.shape"],"metadata":{"id":"4KXyhjpR6d1n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717127946220,"user_tz":-330,"elapsed":10,"user":{"displayName":"Varun G","userId":"00704873837361776795"}},"outputId":"92741714-28f5-47e8-baa6-4d11a790369e"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 62, 62])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# Stepping through nn.MaxPool2d\n","# Print out original image shape:\n","print(f\"Test image original shape: {test_image.shape}\")\n","print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(0).shape}\")\n","\n","max_pool_layer = nn.MaxPool2d(kernel_size=2)\n","\n","test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n","print(f\"Test image through conv: {test_image_through_conv.shape}\")\n","\n","test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n","print(f\"shape after going through conv and max pool layer: {test_image_through_conv_and_max_pool.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGB8x1rtwjz4","executionInfo":{"status":"ok","timestamp":1717127946220,"user_tz":-330,"elapsed":7,"user":{"displayName":"Varun G","userId":"00704873837361776795"}},"outputId":"58e641f9-891d-4b22-85f3-bf170a14788f"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Test image original shape: torch.Size([3, 64, 64])\n","Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n","Test image through conv: torch.Size([1, 10, 62, 62])\n","shape after going through conv and max pool layer: torch.Size([1, 10, 31, 31])\n"]}]},{"cell_type":"code","source":["random_tensor = torch.randn(size=(1,1,2,2))\n","print(f\"\\nRandom Tensor:\\n{random_tensor}\")\n","print(f\"Random Tensor Shape: {random_tensor.shape}\")\n","max_pool_layer = nn.MaxPool2d(kernel_size=2)\n","\n","max_pool_tensor = max_pool_layer(random_tensor)\n","print(f\"Max Pool tensor: \\n{max_pool_tensor}\")\n","print(f\"Max Pool Tensor shape: {max_pool_tensor.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0j33QlRgyET-","executionInfo":{"status":"ok","timestamp":1717127946220,"user_tz":-330,"elapsed":6,"user":{"displayName":"Varun G","userId":"00704873837361776795"}},"outputId":"af955e65-b461-4c5c-bef6-e47c51018598"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Random Tensor:\n","tensor([[[[0.4963, 0.0045],\n","          [0.5534, 0.1379]]]])\n","Random Tensor Shape: torch.Size([1, 1, 2, 2])\n","Max Pool tensor: \n","tensor([[[[0.5534]]]])\n","Max Pool Tensor shape: torch.Size([1, 1, 1, 1])\n"]}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","model_2 = FashionMNISTModelV2(input_shape=1,\n","                              hidden_units=10,\n","                              output_shape = len(class_names)).to(device)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rh3FZ9YzR4D","executionInfo":{"status":"ok","timestamp":1717128051231,"user_tz":-330,"elapsed":714,"user":{"displayName":"Varun G","userId":"00704873837361776795"}},"outputId":"b162f1aa-8515-41ed-c94c-4eaedb4ce121"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n","  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"]}]},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(params=model_2.parameters(),lr=0.1)"],"metadata":{"id":"28gPc0A60CkZ","executionInfo":{"status":"ok","timestamp":1717128584309,"user_tz":-330,"elapsed":2,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def print_train_time(start,end,device):\n","  time = end - start\n","  print(f\"Time taken: {time:.2f} on device {device}\")\n","  return time"],"metadata":{"id":"Fv_Yy_4X1gSz","executionInfo":{"status":"ok","timestamp":1717128572587,"user_tz":-330,"elapsed":592,"user":{"displayName":"Varun G","userId":"00704873837361776795"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","from tqdm.auto import tqdm\n","from timeit import default_timer as timer\n","train_time_start_model_2 = timer()\n","\n","# Train and test model\n","epochs = 3\n","for epoch in tqdm(range(epochs)):\n","  print(f\"Epoch: {epoch}\\n--------\")\n","  train_step(model=model_2,\n","             data_loader=train_dataloader,\n","             loss_fn=loss_fn,\n","             optimizer=optimizer,\n","             accuracy_fn=accuracy_fn,\n","             device=device)\n","  test_step(model=model_2,\n","             data_loader=train_dataloader,\n","             loss_fn=loss_fn,\n","             accuracy_fn=accuracy_fn,\n","             device=device)\n","\n","train_time_end_model_2 = timer()\n","\n","total_time = print_train_time(train_time_start_model_2, train_time_end_model_2, device)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457,"referenced_widgets":["551b6ac2286346fca4a2b8af893d2a49","022e51fc62a94dfcba3ee410a30d0655","d22617b05c474c39811aa1df5c04a28f","ac2805c0f6c9426e8d629aedb73e3156","f2f0ce7adccb43f1adfdcf3c986ad87a","4e6d0dede2364d99ad66914a8849c08d","e86ffc7e6c274988b8b25dcf91c1f44c","3bbde04f663245a4b07a1887ee7dd7eb","af61d0bc1a3e42f98c048fa60eb9f112","578efbc2c0604d0f94596b03bf164ee8","71dd346a1e7945d6b4aa383dae791c32"]},"id":"wY4MBp8D0Stf","executionInfo":{"status":"error","timestamp":1717128587263,"user_tz":-330,"elapsed":587,"user":{"displayName":"Varun G","userId":"00704873837361776795"}},"outputId":"78f4c42b-fc2e-48bd-f38c-5d5905be0654"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"551b6ac2286346fca4a2b8af893d2a49"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0\n","--------\n","torch.Size([32, 10, 14, 14])\n","torch.Size([32, 10, 7, 7])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x490 and 0x10)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-82d164732088>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}\\n--------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   train_step(model=model_2,\n\u001b[0m\u001b[1;32m     12\u001b[0m              \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m              \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-f09c66747cbd>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, data_loader, loss_fn, optimizer, accuracy_fn, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 1. Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 2. Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-22092e95a02f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x490 and 0x10)"]}]}]}